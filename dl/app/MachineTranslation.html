<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Machine Translation | 学习笔记</title>
    <meta name="generator" content="VuePress 1.5.3">
    <link rel="icon" href="/img/logo.ico">
    <link rel="manifest" href="/manifest.json"><link rel='canonical' href='https://bugwriter2.github.io/dl/app/MachineTranslation.html'/>
    <meta name="description" content="博客">
    <meta name="google-site-verification" content="PXbr-y9acmnnEmw1zgCFEydL32xlZIf1OfFmzDFUrzI">
    <link rel="preload" href="/assets/css/0.styles.9ce6ac63.css" as="style"><link rel="preload" href="/assets/js/app.3fa2a2e1.js" as="script"><link rel="preload" href="/assets/js/2.057925ea.js" as="script"><link rel="preload" href="/assets/js/16.776ab4c1.js" as="script"><link rel="prefetch" href="/assets/js/10.9a53695e.js"><link rel="prefetch" href="/assets/js/11.e6f60bd9.js"><link rel="prefetch" href="/assets/js/12.90f3d785.js"><link rel="prefetch" href="/assets/js/13.42e681ed.js"><link rel="prefetch" href="/assets/js/14.7a85d7cd.js"><link rel="prefetch" href="/assets/js/15.402110d9.js"><link rel="prefetch" href="/assets/js/17.4af5340c.js"><link rel="prefetch" href="/assets/js/18.bd060f5e.js"><link rel="prefetch" href="/assets/js/19.ac40939f.js"><link rel="prefetch" href="/assets/js/20.ac68ccd2.js"><link rel="prefetch" href="/assets/js/21.90d4b479.js"><link rel="prefetch" href="/assets/js/22.044d8e2b.js"><link rel="prefetch" href="/assets/js/23.606676bb.js"><link rel="prefetch" href="/assets/js/24.e8a14162.js"><link rel="prefetch" href="/assets/js/25.ebdc5e35.js"><link rel="prefetch" href="/assets/js/26.efd6b8fb.js"><link rel="prefetch" href="/assets/js/27.649d5e23.js"><link rel="prefetch" href="/assets/js/28.1c7ccf18.js"><link rel="prefetch" href="/assets/js/29.f0ca98d8.js"><link rel="prefetch" href="/assets/js/3.7c0ca1fc.js"><link rel="prefetch" href="/assets/js/30.540536d8.js"><link rel="prefetch" href="/assets/js/31.3cc7b8a3.js"><link rel="prefetch" href="/assets/js/32.02879a8f.js"><link rel="prefetch" href="/assets/js/33.b1417b92.js"><link rel="prefetch" href="/assets/js/34.0b5079cd.js"><link rel="prefetch" href="/assets/js/35.2828b1d3.js"><link rel="prefetch" href="/assets/js/36.d0d0971a.js"><link rel="prefetch" href="/assets/js/37.6cc365c3.js"><link rel="prefetch" href="/assets/js/38.a184b552.js"><link rel="prefetch" href="/assets/js/39.84a689f9.js"><link rel="prefetch" href="/assets/js/4.7a06b201.js"><link rel="prefetch" href="/assets/js/40.c2d886c6.js"><link rel="prefetch" href="/assets/js/5.0de0ba0e.js"><link rel="prefetch" href="/assets/js/6.cb2a4e71.js"><link rel="prefetch" href="/assets/js/7.f7f97492.js"><link rel="prefetch" href="/assets/js/8.7c626f1f.js"><link rel="prefetch" href="/assets/js/9.b014d1e7.js">
    <link rel="stylesheet" href="/assets/css/0.styles.9ce6ac63.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">学习笔记</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="博文" class="dropdown-title"><span class="title">博文</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/python/" class="nav-link">
  Python
</a></li><li class="dropdown-item"><!----> <a href="/dv/" class="nav-link">
  Data Visualization
</a></li><li class="dropdown-item"><!----> <a href="/dl/" class="nav-link router-link-active">
  Deep Learning
</a></li><li class="dropdown-item"><!----> <a href="/dc/" class="nav-link">
  Docker
</a></li><li class="dropdown-item"><!----> <a href="/qa/" class="nav-link">
  Q&amp;A
</a></li><li class="dropdown-item"><!----> <a href="/svc/" class="nav-link">
  Backend Services
</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">
  关于
</a></div><div class="nav-item"><a href="https://www.github.com/bugwriter2" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="博文" class="dropdown-title"><span class="title">博文</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/python/" class="nav-link">
  Python
</a></li><li class="dropdown-item"><!----> <a href="/dv/" class="nav-link">
  Data Visualization
</a></li><li class="dropdown-item"><!----> <a href="/dl/" class="nav-link router-link-active">
  Deep Learning
</a></li><li class="dropdown-item"><!----> <a href="/dc/" class="nav-link">
  Docker
</a></li><li class="dropdown-item"><!----> <a href="/qa/" class="nav-link">
  Q&amp;A
</a></li><li class="dropdown-item"><!----> <a href="/svc/" class="nav-link">
  Backend Services
</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">
  关于
</a></div><div class="nav-item"><a href="https://www.github.com/bugwriter2" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Applications</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/dl/app/ImageClassification.html" class="sidebar-link">Image Classification</a></li><li><a href="/dl/app/MachineTranslation.html" aria-current="page" class="active sidebar-link">Machine Translation</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/dl/app/MachineTranslation.html#seq2seq" class="sidebar-link">seq2seq</a></li><li class="sidebar-sub-header"><a href="/dl/app/MachineTranslation.html#bert" class="sidebar-link">Bert</a></li><li class="sidebar-sub-header"><a href="/dl/app/MachineTranslation.html#word-embedding" class="sidebar-link">Word embedding</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/dl/app/MachineTranslation.html#latent-semantic-analysis" class="sidebar-link">latent semantic analysis</a></li><li class="sidebar-sub-header"><a href="/dl/app/MachineTranslation.html#word2vec" class="sidebar-link">word2vec</a></li><li class="sidebar-sub-header"><a href="/dl/app/MachineTranslation.html#glove" class="sidebar-link">GloVe</a></li><li class="sidebar-sub-header"><a href="/dl/app/MachineTranslation.html#bert-embedding" class="sidebar-link">Bert embedding</a></li></ul></li><li class="sidebar-sub-header"><a href="/dl/app/MachineTranslation.html#tokenizer" class="sidebar-link">Tokenizer</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/dl/app/MachineTranslation.html#byte-pair-encoding" class="sidebar-link">Byte Pair Encoding</a></li><li class="sidebar-sub-header"><a href="/dl/app/MachineTranslation.html#byte-level-encoding" class="sidebar-link">Byte Level Encoding</a></li><li class="sidebar-sub-header"><a href="/dl/app/MachineTranslation.html#wordpiece" class="sidebar-link">WordPiece</a></li></ul></li><li class="sidebar-sub-header"><a href="/dl/app/MachineTranslation.html#evaluation" class="sidebar-link">Evaluation</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/dl/app/MachineTranslation.html#similarity" class="sidebar-link">Similarity</a></li></ul></li></ul></li><li><a href="/dl/app/TableRecognition.html" class="sidebar-link">Table Recognition</a></li></ul></section></li><li><a href="/dl/Optimizer.html" class="sidebar-link">Optimizer</a></li><li><a href="/dl/Loss.html" class="sidebar-link">Loss</a></li><li><a href="/dl/Backpropagation.html" class="sidebar-link">Backpropagation</a></li><li><a href="/dl/Pytorch.html" class="sidebar-link">Pytorch</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Tensorflow</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="machine-translation"><a href="#machine-translation" class="header-anchor">#</a> Machine Translation</h1> <h2 id="seq2seq"><a href="#seq2seq" class="header-anchor">#</a> seq2seq</h2> <ul><li><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank" rel="noopener noreferrer">RNN+Attention<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://zhuanlan.zhihu.com/p/47063917" target="_blank" rel="noopener noreferrer">Encoder Decoder Attention<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <h2 id="bert"><a href="#bert" class="header-anchor">#</a> Bert</h2> <p>Bert uses exact the same structure as transformers(proposed in attention is all you need), but is pre-trained in a novel way to facilitate bidirectional learning</p> <p>Besides positional embedding and word embedding, bert proposes a token_type embedding(like segment ids) to extend for other tasks</p> <ul><li><a href="http://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener noreferrer">Transformer1<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <ul><li>multi-head self-attention, relation to other tokens: <span class="vuepress-eq"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mrow><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>n</mi></mrow></msub><mo>∗</mo><msub><mi>k</mi><mrow><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi mathvariant="normal">_</mi><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>n</mi></mrow></msub><mo>=</mo><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><msub><mi>e</mi><mrow><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi mathvariant="normal">_</mi><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">q_{token} * k_{other\_token} = score_{other\_token}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.6597200000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.06144em;vertical-align:-0.367em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.367em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.79756em;vertical-align:-0.367em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.367em;"><span></span></span></span></span></span></span></span></span></span></span> ([batch x from_seq x heads x x embedding_head_size] * [batch x to_seq x heads x embedding_head_size] =&gt; [batch x heads x from_seq x to_seq])</li> <li><code>A [PAD]</code> as input, <code>[PAD]</code> score to <code>A</code> is 0, but <code>A</code> to <code>[PAD]</code> is 0.5. Therefore <code>[PAD]</code> attends to <code>A</code> will not update embedding weights for <code>[PAD]</code>, but <code>A attends to</code>[PAD]<code>will update embedding weights for</code>[PAD]`</li> <li><a href="https://github.com/google-research/bert/issues/58#issuecomment-572287540" target="_blank" rel="noopener noreferrer">positional embedding can be fixed with sinusoidal or a learnable variable<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/" target="_blank" rel="noopener noreferrer">what is sinusoidal<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul></li> <li><a href="https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1" target="_blank" rel="noopener noreferrer">Transformer2<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://zhuanlan.zhihu.com/p/74516930" target="_blank" rel="noopener noreferrer">Layer Norm<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://datascience.stackexchange.com/questions/49522/what-is-gelu-activation" target="_blank" rel="noopener noreferrer">GeLU<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://nlp.stanford.edu/seminar/details/jdevlin.pdf" target="_blank" rel="noopener noreferrer">Pre-training<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <ul><li>Given <code>[MASK]</code>, module is aware that he needs to predict it</li> <li>15% of input tokens are masked by 0.8 <code>[MASK]</code>, 0.1 random and different token and 0.1 original token. <a href="https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270" target="_blank" rel="noopener noreferrer">Reason<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>The output of the <code>[CLS]</code> token is transformed into a 2×1 shaped vector, using a simple classification layer (learned matrices of weights and biases)</li> <li>bert is pre-trained on next-sentence classification, so segment ids is needed for bert pre-training</li> <li>WordPiece tokenizer, ['hacking'] =&gt; ['hack', '##ing']</li> <li>embedding table =&gt; w</li> <li>segment, position =&gt; b
<ul><li>learned position embedding, used by bert</li> <li><a href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/" target="_blank" rel="noopener noreferrer">sinusoidal position<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, this one is fixed but not used by bert</li> <li>segment ids [0, 0, 1] are extend to [seq_len(3), embedding_size] with random weights, all 0' weights are the same and distinct from 1's</li> <li><a href="https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#history" target="_blank" rel="noopener noreferrer">more info<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul></li> <li>the embedding process is like a fc layer, if input =&gt; one hot encoding (inefficient, thus using embedding lookup)</li> <li>only attention mask is needed to avoid [PAD] token affecting weight variables being updated in back-propagation
<img src="https://miro.medium.com/max/700/0*m_kXt3uqZH9e7H4w.png" alt="pre"></li></ul></li> <li>Usage
<img src="https://miro.medium.com/max/700/0*eDC9QUkMHJAp-NJg.JPEG" alt="usage"> <ul><li><a href="http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/" target="_blank" rel="noopener noreferrer">classification with feature extraction(position and segment are ignored for simple understanding)<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://towardsdatascience.com/bert-to-the-rescue-17671379687f" target="_blank" rel="noopener noreferrer">classification with fine tuning (position and segment are ignored for simple understanding)<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul></li> <li><a href="https://github.com/google-research/bert/blob/master/modeling.py" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://medium.com/analytics-vidhya/understanding-bert-architecture-3f35a264b187" target="_blank" rel="noopener noreferrer">Parameter calculation 1<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, <a href="https://github.com/google-research/bert/issues/656#issuecomment-554718760" target="_blank" rel="noopener noreferrer">Parameter calculation 2<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <h2 id="word-embedding"><a href="#word-embedding" class="header-anchor">#</a> Word embedding</h2> <h3 id="latent-semantic-analysis"><a href="#latent-semantic-analysis" class="header-anchor">#</a> latent semantic analysis</h3> <p>SVD， 全局特征的矩阵分解方法</p> <ul><li><a href="https://moj-analytical-services.github.io/NLP-guidance/LSA.html" target="_blank" rel="noopener noreferrer">Reading 1<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://people.eng.unimelb.edu.au/mbouadjenek/papers/wordembed.pdf" target="_blank" rel="noopener noreferrer">Reading 2<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <h3 id="word2vec"><a href="#word2vec" class="header-anchor">#</a> word2vec</h3> <p>局部上下文</p> <p>center and context words. skip-ngram: use center to predict context with neural networks</p> <ul><li>[Reading](https://people.eng.unimelb.edu.au/mbouadjenek/papers/wordembed.pdf</li> <li><a href="https://ruder.io/word-embeddings-softmax/index.html#negativesampling" target="_blank" rel="noopener noreferrer">Negative sampling<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <ul><li>softmax on very large context set is time-consuming</li> <li>noise contrastive estimation converts to binary classification</li> <li>negative sampling to further simply</li></ul></li></ul> <h3 id="glove"><a href="#glove" class="header-anchor">#</a> GloVe</h3> <p>既使用了语料库的全局统计（overall statistics）特征，也使用了局部的上下文特征（即滑动窗口）</p> <ul><li><a href="https://people.eng.unimelb.edu.au/mbouadjenek/papers/wordembed.pdf" target="_blank" rel="noopener noreferrer">Reading 1<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://zhuanlan.zhihu.com/p/42073620" target="_blank" rel="noopener noreferrer">Reading 2<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://github.com/stanfordnlp/GloVe" target="_blank" rel="noopener noreferrer">Back propagation using c<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <h3 id="bert-embedding"><a href="#bert-embedding" class="header-anchor">#</a> Bert embedding</h3> <p>context aware</p> <h2 id="tokenizer"><a href="#tokenizer" class="header-anchor">#</a> Tokenizer</h2> <h3 id="byte-pair-encoding"><a href="#byte-pair-encoding" class="header-anchor">#</a> Byte Pair Encoding</h3> <p>Formed by character n-gram, e.g., <code>ana</code>, <code>app</code>. As in unicode, there are 149k+ characters, hence it requires large number of vocabulary to cover mostly used n-grams. And it is very common to see <code>[UNKNOWN]</code> in model's input.</p> <p><a href="https://huggingface.co/docs/transformers/tokenizer_summary#bytepair-encoding-bpe" target="_blank" rel="noopener noreferrer">Details in huggingface tokenizer summary<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h3 id="byte-level-encoding"><a href="#byte-level-encoding" class="header-anchor">#</a> Byte Level Encoding</h3> <p>A variation of BPE. Use <strong>Byte</strong> as base unit to form n-gram. Only 256 possible choices for base unit, so it covers mostly used n-grams by only 50k+.
<a href="https://zhuanlan.zhihu.com/p/371300063" target="_blank" rel="noopener noreferrer">聚沙成塔：关于tokenization（词元化）的解疑释惑<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h3 id="wordpiece"><a href="#wordpiece" class="header-anchor">#</a> WordPiece</h3> <p>Given a training corpus and expected vocabulary size D, find the optimal vocabulary list with size D which produces minimal number of tokens after tokenization with it.</p> <h4 id="bottom-up"><a href="#bottom-up" class="header-anchor">#</a> Bottom up</h4> <p>Bottom up: described poorly in <a href="https://research.google/pubs/pub37842/" target="_blank" rel="noopener noreferrer">Japanese and Korean Voice Search<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>. Similar with <code>Byte-Paired Encoding</code>, except that it merge small tokens which increase the likelihood on the training data the most.</p> <p>In the paper, it is confusing:</p> <p>they need to &quot;maximize the likelihood&quot; of each pair, by building a new Language Model (LM) each step - they don't say what constitutes a LM</p> <p>In <a href="https://huggingface.co/docs/transformers/tokenizer_summary#wordpiece" target="_blank" rel="noopener noreferrer">huggingface<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, it is interpreted as:</p> <p>So what does this mean exactly? Referring to the previous example, maximizing the likelihood of the training data is equivalent to finding the symbol pair, whose probability divided by the probabilities of its first symbol followed by its second symbol is the greatest among all symbol pairs. E.g. &quot;u&quot;, followed by &quot;g&quot; would have only been merged if the probability of &quot;ug&quot; divided by &quot;u&quot;, &quot;g&quot; would have been greater than for any other symbol pair. Intuitively, WordPiece is slightly different to BPE in that it evaluates what it loses by merging two symbols to ensure it’s worth it.</p> <p>In <a href="https://zhuanlan.zhihu.com/p/445686202" target="_blank" rel="noopener noreferrer">zhihu<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, it is interpreted as:</p> <p>合并比如决策树，在某个节点拆分前，会考虑到拆分前和拆分后的信息增益，比如我们选择了x这个特征进行拆分，那么在拆分前，其信息熵为 <span class="vuepress-eq"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">-log(p(y)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span></span>, 拆分后为: <span class="vuepress-eq"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mn>1</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mn>2</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">-log(p(y1)) - log(p(y2))</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">1</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">2</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span> , 也就是说，拆分前后的信息增益为：<span class="vuepress-eq"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mn>1</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mn>2</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">-log(p(y1)) - log(p(y2)) + log(p(y))</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">1</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">2</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span>， 整合后的结果是： <span class="vuepress-eq"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mn>1</mn><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mn>2</mn><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\log \left(\frac{p(y)}{p(y 1) p(y 2)}\right)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mord mathdefault mtight">p</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span></span>, 也就是说&quot;e&quot;和&quot;s&quot;的合并考虑的是概率上的效果提升，而不是单纯的频次</p> <h4 id="top-down"><a href="#top-down" class="header-anchor">#</a> Top down</h4> <p>Used by bert. Starting with words and breaking them down into smaller components until they hit the frequency threshold, or can't be broken down further. For Japanese, Chinese and Korean this top-down approach doesn't work since there are no explicit word units to start with.</p> <p><a href="https://www.tensorflow.org/text/guide/subwords_tokenizer#choosing_the_vocabulary" target="_blank" rel="noopener noreferrer">Details in tensorflow text library<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h2 id="evaluation"><a href="#evaluation" class="header-anchor">#</a> Evaluation</h2> <h3 id="similarity"><a href="#similarity" class="header-anchor">#</a> Similarity</h3> <p>way 1 <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" target="_blank" rel="noopener noreferrer"><code>sklearn.feature_extraction.text.CountVectorizer</code><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>: tokenize corpus first, and get a count matrix for prediction and ground truth respectively which can be used to compute the matrix similarity score using cosine later</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer
<span class="token keyword">import</span> scipy

<span class="token comment"># supports both char and word</span>
vec <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span>ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> analyzer<span class="token operator">=</span><span class="token string">'char'</span><span class="token punctuation">)</span>

vec<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'sentence 1'</span><span class="token punctuation">,</span> <span class="token string">'sentence 2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

m1 <span class="token operator">=</span> vec<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>prediction<span class="token punctuation">)</span><span class="token punctuation">.</span>todense<span class="token punctuation">(</span><span class="token punctuation">)</span>
m2 <span class="token operator">=</span> vec<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>truth<span class="token punctuation">)</span><span class="token punctuation">.</span>todense<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">score_calc</span><span class="token punctuation">(</span>v1<span class="token punctuation">,</span> v2<span class="token punctuation">)</span><span class="token punctuation">:</span>
    score <span class="token operator">=</span> scipy<span class="token punctuation">.</span>spatial<span class="token punctuation">.</span>distance<span class="token punctuation">.</span>cosine<span class="token punctuation">(</span>v1<span class="token punctuation">,</span> v2<span class="token punctuation">)</span>
    score <span class="token operator">=</span> <span class="token number">0</span> <span class="token keyword">if</span> pd<span class="token punctuation">.</span>isna<span class="token punctuation">(</span>score<span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token number">1</span> <span class="token operator">-</span> score
    <span class="token keyword">return</span> score

tmp_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>m1<span class="token punctuation">,</span> m2<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
scores <span class="token operator">=</span> tmp_df<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> score_calc<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre></div><p>way 2 Levenshtein distance (number of additions, substitutions, etc.)</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> fuzzywuzzy <span class="token keyword">import</span> fuzz

Str1 <span class="token operator">=</span> <span class="token string">&quot;Apple Inc.&quot;</span>
Str2 <span class="token operator">=</span> <span class="token string">&quot;apple Inc&quot;</span>
Ratio <span class="token operator">=</span> fuzz<span class="token punctuation">.</span>ratio<span class="token punctuation">(</span>Str1<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>Str2<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><div class="custom-block tip"><p class="custom-block-title">references</p> <ul><li><a href="https://www.datacamp.com/community/tutorials/fuzzy-string-python" target="_blank" rel="noopener noreferrer">How to use fuzzywuzzy<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/" target="_blank" rel="noopener noreferrer">Fuzzywuzzy explanation<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul></div></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">3/27/2023, 4:00:33 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/dl/app/ImageClassification.html" class="prev">
        Image Classification
      </a></span> <span class="next"><a href="/dl/app/TableRecognition.html">
        Table Recognition
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.3fa2a2e1.js" defer></script><script src="/assets/js/2.057925ea.js" defer></script><script src="/assets/js/16.776ab4c1.js" defer></script>
  </body>
</html>
