(window.webpackJsonp=window.webpackJsonp||[]).push([[23],{391:function(t,a,e){"use strict";e.r(a);var s=e(11),n=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"keras"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#keras"}},[t._v("#")]),t._v(" "),e("a",{attrs:{href:"https://www.tensorflow.org/guide/keras/sequential_model",target:"_blank",rel:"noopener noreferrer"}},[t._v("Keras"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("Functional api writes model component line by line and then uses "),e("code",[t._v("Model(input, output)")]),t._v(" to get a encapsulated model. After building a model using functional api, the graph and weights are initialized and thus checkpoint can be loaded and checked immediately.")]),t._v(" "),e("p",[t._v("Module sub_classing encapsulated the model inherently, but weights and graphs are lazy-initialized, so "),e("code",[t._v("model.summary()")]),t._v(" or "),e("code",[t._v("checkpoint.restore(ckpt).assert_consumed()")]),t._v(" only works after model is called.")]),t._v(" "),e("p",[e("code",[t._v("tf.keras.layers.Layer")]),t._v(" inherits "),e("code",[t._v("tf.Module")]),t._v(", and "),e("code",[t._v("tf.keras.Model")]),t._v(" inherits "),e("code",[t._v("tf.keras.layers.Layer")]),t._v(". "),e("code",[t._v("._layers")]),t._v(" is introduced in "),e("code",[t._v("tf.keras.layers.Layer")]),t._v(" and "),e("code",[t._v("layers")]),t._v(" is introduced in "),e("code",[t._v("tf.keras.Model")]),t._v(". As a result, "),e("code",[t._v("tf.keras.Model")]),t._v(" has both "),e("code",[t._v("layers")]),t._v(" and "),e("code",[t._v("._layers")]),t._v(" attribute whereas "),e("code",[t._v("tf.keras.layers.Layer")]),t._v(" only has "),e("code",[t._v("._layers")]),t._v(" attribute.")]),t._v(" "),e("p",[e("code",[t._v("tf.keras.layers.Layer")]),t._v(" has a "),e("code",[t._v("get_weights")]),t._v(" method, by which a list of numpy values of all encapsulated variable weights can be obtained. Inside "),e("code",[t._v("tf.keras.layers.Layer")]),t._v(", there can be "),e("code",[t._v("tf.Variable")]),t._v(" and other "),e("code",[t._v("tf.keras.layers.Layer")])]),t._v(" "),e("div",{staticClass:"custom-block tip"},[e("p",{staticClass:"custom-block-title"},[t._v("custom training logic(from tf2.2)")]),t._v(" "),e("p",[t._v("See "),e("a",{attrs:{href:"https://keras.io/guides/customizing_what_happens_in_fit/",target:"_blank",rel:"noopener noreferrer"}},[t._v("resource 1"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("See "),e("a",{attrs:{href:"https://towardsdatascience.com/tensorflow-2-2-and-a-custom-training-logic-16fa72934ac3",target:"_blank",rel:"noopener noreferrer"}},[t._v("resource 2"),e("OutboundLink")],1)])]),t._v(" "),e("h2",{attrs:{id:"model-customization"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#model-customization"}},[t._v("#")]),t._v(" Model customization")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("CustomModel")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("keras"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Model"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("train_step")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Unpack the data. Its structure depends on your model and")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# on what you pass to `fit()`.")]),t._v("\n        x"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# sample weight can be added here")]),t._v("\n\n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" tf"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("GradientTape"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" tape"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            y_pred "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" training"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Forward pass")]),t._v("\n            "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Compute the loss value")]),t._v("\n            "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (the loss function is configured in `compile()`)")]),t._v("\n            loss "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("compiled_loss"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_pred"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" regularization_losses"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("self"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("losses"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# additional loss added")]),t._v("\n\n        "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Compute gradients")]),t._v("\n        trainable_vars "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("trainable_variables\n        gradients "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tape"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gradient"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trainable_vars"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Update weights")]),t._v("\n        self"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optimizer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply_gradients"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("zip")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("gradients"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trainable_vars"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Update metrics (includes all the metrics that tracks the loss)")]),t._v("\n        self"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("compiled_metrics"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update_state"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_pred"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Return a dict mapping metric names to current value")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("m"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" m"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("result"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" m "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metrics"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("call")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inputs"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("args"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" train"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mask"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v("kwargs"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# args and kwargs are not recommended as poor hygiene check")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# more at tf 2.1: https://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/keras/engine/base_layer.py#L628")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# more at tf 2.3: https://github.com/tensorflow/tensorflow/blob/fcc4b966f1265f466e82617020af93670141b009/tensorflow/python/keras/engine/base_layer.py#L875")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("pass")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n        Avoid declaration of tf.Variable inside model call. Model training is fine but export leads to error. Reason:\n        When a tf.Variable is created in a tf.function, it will be lifted to the default graph context for initialization.\n        However, if the variable has external dependency such as a placeholder input, the variable will fail to be lifted to\n        the default graph context. When one defines a sparse operation in their model, the gradient aggregation variable will fail to be initialized. More info: https://github.com/horovod/horovod/pull/3499\n        """')]),t._v("\n")])])]),e("p",[t._v("See customized optimizer "),e("a",{attrs:{href:"https://github.com/huggingface/transformers/blob/13842e413cfa95893185e4330fab61f6f70d19e8/src/transformers/optimization_tf.py#L152",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),e("OutboundLink")],1)]),t._v(" "),e("div",{staticClass:"custom-block tip"},[e("p",{staticClass:"custom-block-title"},[t._v("Valid Layers")]),t._v(" "),e("p",[t._v("Only layers exist in both "),e("code",[t._v("__init__")]),t._v(" / "),e("code",[t._v("build")]),t._v(" and "),e("code",[t._v("call")]),t._v(" are effective ones (saved in checkpoint)")])]),t._v(" "),e("h2",{attrs:{id:"callbacks"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#callbacks"}},[t._v("#")]),t._v(" Callbacks")]),t._v(" "),e("p",[t._v("Using callbacks during "),e("code",[t._v("model.fit")]),t._v(" has some restrictions")]),t._v(" "),e("p",[t._v("ProgbarLogger Callback:")]),t._v(" "),e("ul",[e("li",[e("strong",[t._v("tf2.1")]),t._v(": ProgbarLogger is the last callback and can only be muted but not customized if using "),e("code",[t._v("model.fit")])]),t._v(" "),e("li",[e("strong",[t._v("tf2.2")]),t._v(": ProgbarLogger can be customized given "),e("code",[t._v("CallbackList")]),t._v(" if using "),e("code",[t._v("model.fit")])]),t._v(" "),e("li",[t._v("ProgbarLogger is reset every epoch, so in batch logs have the same display")]),t._v(" "),e("li",[t._v("ProgbarLogger averages the loss, but not other metrics(stateful)")])]),t._v(" "),e("p",[t._v("Tensorboard Callback:")]),t._v(" "),e("ul",[e("li",[t._v("Tensorboard callback always logs per epoch even if "),e("code",[t._v("update_freq=int")])]),t._v(" "),e("li",[t._v("if metric name starts with "),e("code",[t._v("val_")]),t._v("\b, Tensorboard callback logs the value using validation writer (logs in validation folder)")]),t._v(" "),e("li",[t._v("In batch, tensorboard callback has no validation writer")])]),t._v(" "),e("h2",{attrs:{id:"precision"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#precision"}},[t._v("#")]),t._v(" Precision")]),t._v(" "),e("p",[t._v("In "),e("code",[t._v("tf.keras.layers.Layer")]),t._v(" constructor, there is "),e("code",[t._v("dtype")]),t._v(" argument which will cast "),e("code",[t._v("inputs")]),t._v(" in "),e("code",[t._v("call(self, inputs, **kwargs)")]),t._v(" to "),e("code",[t._v("dtype")]),t._v(", if the "),e("code",[t._v("inputs")]),t._v(" is the same type as "),e("code",[t._v("dtype")]),t._v(" but precision is different.")]),t._v(" "),e("h2",{attrs:{id:"shape"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#shape"}},[t._v("#")]),t._v(" Shape")]),t._v(" "),e("p",[t._v("If dealing with unknown batch size while building the model graph, use "),e("code",[t._v("tf.shape(variable_tensor)")]),t._v(" instead of "),e("code",[t._v("variable_tensor.shape")]),t._v(" can solve the "),e("code",[t._v("cannot convert a partially known tensorshape to a tensor")]),t._v(" exception. It is because the former gives a tensor whereas the later returns TensorShape")])])}),[],!1,null,null,null);a.default=n.exports}}]);