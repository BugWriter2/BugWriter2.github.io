(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{370:function(t,s,a){"use strict";a.r(s);var n=a(11),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"checkpoint"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#checkpoint"}},[t._v("#")]),t._v(" Checkpoint")]),t._v(" "),a("p",[t._v("tf 2 checkpoint is object based.")]),t._v(" "),a("h2",{attrs:{id:"tf-train-checkpoint"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tf-train-checkpoint"}},[t._v("#")]),t._v(" tf.train.Checkpoint")]),t._v(" "),a("h3",{attrs:{id:"basics"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#basics"}},[t._v("#")]),t._v(" Basics")]),t._v(" "),a("p",[a("code",[t._v("save")]),t._v(" and "),a("code",[t._v("restore")]),t._v(" are used in pair, while "),a("code",[t._v("read")]),t._v(" and "),a("code",[t._v("write")]),t._v(" are used in pair. For the first pair, they maintain a "),a("code",[t._v("save_counter")]),t._v(" which is used to name ckpt files. Regards with the last pair, naming of ckpt should be self-implemented.")]),t._v(" "),a("p",[a("code",[t._v("restore")]),t._v(" or "),a("code",[t._v("read")]),t._v(" returns a status object, which have the following four check mechanism:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("assert_consumed")]),t._v(": all checkpoint variables are "),a("strong",[t._v("restored")]),t._v(" into model and there are no additional model variable which has no mapping")]),t._v(" "),a("li",[a("code",[t._v("assert_existing_objects_matched")]),t._v(": every "),a("strong",[t._v("built")]),t._v(" model variable must exist in the transitive dependencies(children or grandchildren node) in checkpoint graph.\n"),a("ul",[a("li",[t._v("if model is yet to be built, this check will pass too.")]),t._v(" "),a("li",[t._v("Any unrestored variable in checkpoint will raise warnings.")])])]),t._v(" "),a("li",[a("code",[t._v("assert_nontrivial_match")]),t._v(": there must exist some variables in model which exist in the transitive dependencies(children or grandchildren node) in checkpoint graph\n"),a("ul",[a("li",[t._v("For "),a("code",[t._v("restore")]),t._v(" and "),a("code",[t._v("save")]),t._v(" pair, this check will always pass due to "),a("code",[t._v("save_counter")]),t._v(".")]),t._v(" "),a("li",[t._v("Any unrestored variable in checkpoint will raise warnings.")])])]),t._v(" "),a("li",[a("code",[t._v("expect_partial")]),t._v(": no check and no warnings")])]),t._v(" "),a("p",[t._v("Before tensorflow 2.4, checkpoint saved using "),a("code",[t._v("model.save_weights")]),t._v(" cannot be loaded with "),a("code",[t._v("tf.train.Checkpoint(key=model)")]),t._v(" because:")]),t._v(" "),a("img",{attrs:{src:"https://user-images.githubusercontent.com/26344199/180922117-20b4d005-c322-4a46-9684-f3c38e8dd1d3.png",height:"200px"}}),t._v(" "),a("p",[t._v("After tensorflow 2.4, "),a("code",[t._v("root")]),t._v(" keyword argument replaced the position argument and:")]),t._v(" "),a("img",{attrs:{src:"https://user-images.githubusercontent.com/26344199/180922369-ab944b4c-c9fe-4eee-88f4-72cfd22838aa.png",height:"200px"}}),t._v(" "),a("h3",{attrs:{id:"variable-names"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#variable-names"}},[t._v("#")]),t._v(" Variable Names")]),t._v(" "),a("p",[t._v("Variable name serves as the edge in graph and it is important to understand its generation mechanism")]),t._v(" "),a("p",[t._v("When a checkpoint is saved, variable label is switched first before saving. For example:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Regress")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("super")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Regress"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dense"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" activation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dense"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" activation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'heihei'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n     self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dense"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" activation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("call")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nr "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Regress"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("some_input"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# if no name provided, class name is used; if class names conflict, _x number is added as a suffix")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# variable name of dense1: regress/dense/kernel:0")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# variable name of dense2: regress/heihei/kernel:0")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# variable name of dense3: regress/dense_1/kernel:0")]),t._v("\nr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("variables\n\ncheckpoint_directory "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./training_checkpoints'")]),t._v("\ncheckpoint_prefix "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pathlib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("checkpoint_directory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ckpt'")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# checkpoint use different label naming mechanism")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# variable name in python code and argument passed are used")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# variable name of dense1: zy/dense1/kernel/.ATTRIBUTES/VARIABLE_VALUE")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# variable name of dense2: zy/dense2/kernel/.ATTRIBUTES/VARIABLE_VALUE")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# variable name of dense3: zy/dense3/kernel/.ATTRIBUTES/VARIABLE_VALUE")]),t._v("\ncheckpoint "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("zy"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("r"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ncheckpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("save"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file_prefix"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("checkpoint_prefix"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"practices"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#practices"}},[t._v("#")]),t._v(" Practices")]),t._v(" "),a("p",[t._v("Example - save checkpoint in "),a("code",[t._v("Regress")]),t._v(" model and restore it in "),a("code",[t._v("RegressToRestore")]),t._v(":")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\nCompile Fit Save\n\nBuild (Compile) Load (Compile) Fit\nDelayed Restore\nBuild first to create internal variables\n"""')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tensorflow "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" tf\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pathlib\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Regress")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("super")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Regress"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dense"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" activation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dense"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" activation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("softmax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" input_shape"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ...")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("call")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("dummy_input")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("constant"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Regress"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nopt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optimizers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Adam"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("compile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mean_squared_error"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" optimizer"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("opt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\nexample_x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("constant"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nexample_y "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("constant"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("example_x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" example_y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epochs"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\ncheckpoint_directory "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./training_checkpoints'")]),t._v("\ncheckpoint_prefix "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pathlib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("checkpoint_directory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ckpt'")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# label in ckpt => variable")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# regress/dense/kernel:0 => zy/kernel/.ATTRIBUTES/VARIABLE_VALUE")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [('_CHECKPOINTABLE_OBJECT_GRAPH', []), ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', [])]")]),t._v("\ncheckpoint "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("zy"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" opt"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("opt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ncheckpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("save"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file_prefix"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("checkpoint_prefix"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RegressToRestore")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("super")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RegressToRestore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense3 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dense"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" activation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense4 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dense"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" activation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("softmax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" input_shape"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ...")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("call")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("dummy_input")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("constant"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RegressToRestore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# model.build(input_shape=(None,1))")]),t._v("\nmodel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dummy_input"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\nopt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optimizers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Adam"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# same argument name => zy/kernel/.ATTRIBUTES/VARIABLE_VALUE => graph matches")]),t._v("\ncheckpoint "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("zy"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" opt"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("opt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nstatus "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("restore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("latest_checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("checkpoint_directory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\nmodel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("compile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mean_squared_error"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" optimizer"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("opt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nexample_x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("constant"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nexample_y "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("constant"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("example_x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" example_y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epochs"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\nstatus"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("assert_consumed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Remark:")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("To load a model from checkpoint, the model "),a("a",{attrs:{href:"https://github.com/tensorflow/tensorflow/issues/29729",target:"_blank",rel:"noopener noreferrer"}},[t._v("must be built first"),a("OutboundLink")],1),t._v(".")])]),t._v(" "),a("li",[a("p",[t._v("To mute the warnings "),a("code",[t._v("Unresolved object in checkpoint: (root).optimizer.beta_1")]),t._v(", the model "),a("a",{attrs:{href:"https://github.com/tensorflow/tensorflow/issues/33150#issuecomment-574517363",target:"_blank",rel:"noopener noreferrer"}},[t._v("must be fit"),a("OutboundLink")],1),t._v(" or use "),a("code",[t._v("expect_partial()")]),t._v(".")])]),t._v(" "),a("li",[a("p",[t._v("To read variables inside a checkpoint:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("list_variables"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ckpt_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])]),t._v(" "),a("p",[t._v("There are two ways to load a sub graph by "),a("code",[t._v("tf.train.Checkpoint")]),t._v(":")]),t._v(" "),a("ul",[a("li",[t._v("save full model in checkpoint and embed the sub graph to be restored in a fake structure")]),t._v(" "),a("li",[t._v("save both full and sub graph in checkpoint")])]),t._v(" "),a("p",[t._v("No matter which method, without calling "),a("code",[t._v("expect_partial")]),t._v(", there might be warnings related to unresolved variables in checkpoint")]),t._v(" "),a("p",[t._v("Example - save checkpoint in "),a("code",[t._v("Net")]),t._v(" and restore a sub graph only:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Model")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Net")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""A simple linear model."""')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("super")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Net"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("l1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dense"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("call")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("l1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nnet "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Net"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Way 1: embed the sub graph to be restored in a fake structure")]),t._v("\nckpt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("step"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" optimizer"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("opt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" net"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("net"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" iterator"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("iterator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmanager "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("CheckpointManager"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ckpt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./tf_ckpts'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_to_keep"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmanager"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("save"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nto_restore "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zeros"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("to_restore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# All zeros")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Fake structure")]),t._v("\nfake_layer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bias"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("to_restore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nfake_net "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("l1"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("fake_layer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnew_root "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("net"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("fake_net"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nstatus "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" new_root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("restore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("latest_checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./tf_ckpts/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"row",staticStyle:{display:"flex",height:"200px"}},[a("div",{staticClass:"column",staticStyle:{flex:"50%",padding:"5px"}},[a("img",{staticStyle:{width:"100%"},attrs:{src:"https://www.tensorflow.org/images/guide/whole_checkpoint.svg"}})]),t._v(" "),a("div",{staticClass:"column",staticStyle:{flex:"50%",padding:"5px"}},[a("img",{staticStyle:{width:"100%",height:"100%"},attrs:{src:"https://www.tensorflow.org/images/guide/partial_checkpoint.svg"}})])]),t._v(" "),a("p",[t._v("Another method:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Way 2: save both full model and sub graph in checkpoint")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Note that variable label is slightly altered. However, this does not affect full model restoration")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# net/l1/kernel/.ATTRIBUTES/VARIABLE_VALUE, full model variable outside sub graph")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# bias/.ATTRIBUTES/VARIABLE_VALUE, variable in sub graph")]),t._v("\nckpt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("net"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("net"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bias"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("net"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("l1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bias"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmanager "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("CheckpointManager"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ckpt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./tf_ckpts'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_to_keep"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmanager"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("save"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nto_restore "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zeros"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("to_restore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# All zeros")]),t._v("\nrestore_ckpt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bias"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("to_restore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nstatus "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" restore_ckpt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("restore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("latest_checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./tf_ckpts/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nnet2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Net"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrestore_ckpt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("net"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("net2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# full model can also be restored")]),t._v("\n")])])]),a("p",[t._v("Example - Adding a new layer in existing model")]),t._v(" "),a("p",[t._v("tensorflow checkpoint restoration is smart enough. If model adds an additional layer, tensorflow can find the partial structure to load the previous saved weights.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# restore weight")]),t._v("\nnew_model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" build_new_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# additional sub_layer3 is added")]),t._v("\nlatest_check_point "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("latest_checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'old_ckpt'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# model with two sub_layer")]),t._v("\nckpt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'model'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" new_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nckpt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("restore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("latest_check_point"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"tf-train-checkpointmanager"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tf-train-checkpointmanager"}},[t._v("#")]),t._v(" tf.train.CheckpointManager")]),t._v(" "),a("p",[t._v("Manages multiple checkpoints by keeping some and deleting unneeded ones.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tensorflow "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" tf\ncheckpoint "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmanager "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("CheckpointManager"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" directory"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/tmp/model"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_to_keep"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nstatus "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("restore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("manager"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("latest_checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"tf-train-load-checkpoint"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tf-train-load-checkpoint"}},[t._v("#")]),t._v(" tf.train.load_checkpoint")]),t._v(" "),a("p",[t._v("returns CheckpointReader, which can get variable_to_shape map and variable_to_dtype map")]),t._v(" "),a("h2",{attrs:{id:"tf-keras-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tf-keras-model"}},[t._v("#")]),t._v(" tf.keras.Model")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("save_weights"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    filepath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" overwrite"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" save_format"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" options"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nload_weights"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    filepath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" by_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" skip_mismatch"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" options"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);